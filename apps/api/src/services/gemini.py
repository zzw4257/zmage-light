"""
Gemini AI æœåŠ¡
"""
import json
import base64
from typing import List, Dict, Any, Optional
import numpy as np

from src.config import settings


class GeminiService:
    """Gemini AI æœåŠ¡"""
    
    def __init__(self):
        self.api_key = settings.gemini_api_key
        self._client = None
    
    @property
    def client(self):
        """å»¶è¿Ÿåˆå§‹åŒ–å®¢æˆ·ç«¯"""
        if not self.api_key or self.api_key == "YOUR_GEMINI_API_KEY":
            return None
        if self._client is None:
            from google import genai
            try:
                self._client = genai.Client(api_key=self.api_key)
            except Exception as e:
                print(f"Failed to initialize Gemini client: {e}")
                return None
        return self._client
    
    async def analyze_image(self, image_data: bytes, mime_type: str = "image/jpeg") -> Dict[str, Any]:
        """
        åˆ†æå›¾ç‰‡ï¼Œç”Ÿæˆæ ‡é¢˜ã€æè¿°ã€æ ‡ç­¾
        """
        if not self.client:
            return {
                "title": "å›¾ç‰‡èµ„äº§",
                "description": "ç”±äºæœªé…ç½® AI æœåŠ¡ï¼Œæš‚æ— è¯¦ç»†æè¿°ã€‚",
                "tags": ["æœªåˆ†æ"],
                "ocr_text": "",
                "objects": [],
                "scene": "",
                "colors": []
            }

        from google.genai import types
        
        prompt = """è¯·åˆ†æè¿™å¼ å›¾ç‰‡ï¼Œå¹¶ä»¥ JSON æ ¼å¼è¿”å›ä»¥ä¸‹ä¿¡æ¯ï¼š
{
    "title": "ä¸€å¥è¯æ ‡é¢˜ï¼ˆç®€æ´ã€æè¿°æ€§ï¼‰",
    "description": "è¯¦ç»†æè¿°ï¼ˆ2-3å¥è¯ï¼ŒåŒ…å«åœºæ™¯ã€ä¸»ä½“ã€æ°›å›´ç­‰ï¼‰",
    "tags": ["æ ‡ç­¾1", "æ ‡ç­¾2", "æ ‡ç­¾3", "æ ‡ç­¾4", "æ ‡ç­¾5"],
    "ocr_text": "å›¾ç‰‡ä¸­çš„æ–‡å­—ï¼ˆå¦‚æœæœ‰çš„è¯ï¼Œå¦åˆ™ä¸ºç©ºå­—ç¬¦ä¸²ï¼‰",
    "objects": ["è¯†åˆ«åˆ°çš„ç‰©ä½“1", "ç‰©ä½“2"],
    "scene": "åœºæ™¯ç±»å‹ï¼ˆå¦‚ï¼šå®¤å†…ã€æˆ·å¤–ã€è‡ªç„¶ã€åŸå¸‚ç­‰ï¼‰",
    "colors": ["ä¸»è¦é¢œè‰²1", "é¢œè‰²2"]
}

è¦æ±‚ï¼š
1. æ ‡ç­¾è¦å…·ä½“ã€å¯æœç´¢ï¼ŒåŒ…å«ç‰©ä½“ã€åœºæ™¯ã€æƒ…æ„Ÿã€é£æ ¼ç­‰
2. æè¿°è¦è¯¦ç»†ä½†ä¸å†—é•¿
3. å¦‚æœæœ‰æ–‡å­—ï¼Œå®Œæ•´æå–
4. åªè¿”å› JSONï¼Œä¸è¦å…¶ä»–å†…å®¹"""
        
        try:
            response = self.client.models.generate_content(
                model="gemini-2.5-flash",
                contents=[
                    types.Content(
                        parts=[
                            types.Part(
                                inline_data=types.Blob(
                                    mime_type=mime_type,
                                    data=image_data
                                )
                            ),
                            types.Part(text=prompt)
                        ]
                    )
                ]
            )
            
            # è§£æ JSON å“åº”
            text = response.text.strip()
            # ç§»é™¤å¯èƒ½çš„ markdown ä»£ç å—æ ‡è®°
            if text.startswith("```json"):
                text = text[7:]
            elif text.startswith("```"):
                text = text[3:]
            if text.endswith("```"):
                text = text[:-3]
            
            result = json.loads(text.strip())
            return result
            
        except Exception as e:
            print(f"Gemini å›¾ç‰‡åˆ†æå¤±è´¥: {e}")
            return {
                "title": "",
                "description": "",
                "tags": [],
                "ocr_text": "",
                "objects": [],
                "scene": "",
                "colors": []
            }
    
    async def analyze_video(self, video_path: str) -> Dict[str, Any]:
        """
        åˆ†æè§†é¢‘ï¼Œç”Ÿæˆæ‘˜è¦å’Œæ ‡ç­¾
        """
        if not self.client:
            return {
                "title": "è§†é¢‘èµ„äº§",
                "description": "ç”±äºæœªé…ç½® AI æœåŠ¡ï¼Œæš‚æ— è¯¦ç»†æè¿°ã€‚",
                "tags": ["æœªåˆ†æ"],
                "key_moments": [],
                "transcript": ""
            }

        prompt = """è¯·åˆ†æè¿™ä¸ªè§†é¢‘ï¼Œå¹¶ä»¥ JSON æ ¼å¼è¿”å›ä»¥ä¸‹ä¿¡æ¯ï¼š
{
    "title": "è§†é¢‘æ ‡é¢˜",
    "description": "è§†é¢‘å†…å®¹æè¿°",
    "tags": ["æ ‡ç­¾1", "æ ‡ç­¾2", "æ ‡ç­¾3"],
    "key_moments": [
        {"time": "00:00", "description": "å…³é”®æ—¶åˆ»æè¿°"}
    ],
    "transcript": "è§†é¢‘ä¸­çš„å¯¹è¯æˆ–æ—ç™½ï¼ˆå¦‚æœæœ‰ï¼‰"
}

åªè¿”å› JSONï¼Œä¸è¦å…¶ä»–å†…å®¹"""

        try:
            # ä¸Šä¼ è§†é¢‘æ–‡ä»¶
            video_file = self.client.files.upload(file=video_path)
            
            response = self.client.models.generate_content(
                model="gemini-2.5-flash",
                contents=[video_file, prompt]
            )
            
            text = response.text.strip()
            if text.startswith("```json"):
                text = text[7:]
            elif text.startswith("```"):
                text = text[3:]
            if text.endswith("```"):
                text = text[:-3]
            
            return json.loads(text.strip())
            
        except Exception as e:
            print(f"Gemini è§†é¢‘åˆ†æå¤±è´¥: {e}")
            return {
                "title": "",
                "description": "",
                "tags": [],
                "key_moments": [],
                "transcript": ""
            }
    
    async def generate_embedding(self, text: str, task_type: str = "RETRIEVAL_DOCUMENT") -> List[float]:
        """
        ç”Ÿæˆæ–‡æœ¬å‘é‡åµŒå…¥
        """
        if not self.client:
            return [0.0] * settings.embedding_dimension

        from google.genai import types
        
        try:
            result = self.client.models.embed_content(
                model="gemini-embedding-001",
                contents=text,
                config=types.EmbedContentConfig(
                    output_dimensionality=settings.embedding_dimension,
                    task_type=task_type,
                ),
            )
            
            vec = np.array(result.embeddings[0].values, dtype=np.float32)
            # å½’ä¸€åŒ–
            vec = vec / (np.linalg.norm(vec) + 1e-12)
            return vec.tolist()
            
        except Exception as e:
            print(f"Gemini åµŒå…¥ç”Ÿæˆå¤±è´¥: {e}")
            return [0.0] * settings.embedding_dimension
    
    async def generate_query_embedding(self, query: str) -> List[float]:
        """ç”ŸæˆæŸ¥è¯¢å‘é‡"""
        return await self.generate_embedding(query, task_type="RETRIEVAL_QUERY")
    
    async def suggest_albums(
        self,
        assets_info: List[Dict[str, Any]],
        existing_albums: List[str],
    ) -> List[Dict[str, Any]]:
        if not self.client:
            return []

        prompt = f"""æ ¹æ®ä»¥ä¸‹èµ„äº§ä¿¡æ¯ï¼Œå»ºè®®åˆ›å»ºæ–°çš„ç›¸å†Œã€‚

å·²æœ‰ç›¸å†Œï¼š{', '.join(existing_albums) if existing_albums else 'æ— '}

èµ„äº§ä¿¡æ¯ï¼š
{json.dumps(assets_info, ensure_ascii=False, indent=2)}

è¯·åˆ†æè¿™äº›èµ„äº§ï¼Œæ‰¾å‡ºå¯ä»¥å½’ç±»çš„ä¸»é¢˜ã€äº‹ä»¶ã€æ—¶é—´æ®µæˆ–åœºæ™¯ï¼Œå»ºè®®åˆ›å»ºç›¸å†Œã€‚

ä»¥ JSON æ ¼å¼è¿”å›å»ºè®®ï¼š
{{
    "suggestions": [
        {{
            "name": "ç›¸å†Œåç§°",
            "description": "ç›¸å†Œæè¿°",
            "reason": "å»ºè®®ç†ç”±ï¼ˆä¸ºä»€ä¹ˆè¿™äº›èµ„äº§åº”è¯¥å½’ä¸ºä¸€ä¸ªç›¸å†Œï¼‰",
            "asset_ids": [1, 2, 3],
            "cover_asset_id": 1,
            "confidence": 0.85
        }}
    ]
}}

è¦æ±‚ï¼š
1. ç›¸å†Œåç§°è¦æœ‰æ„ä¹‰ã€æ˜“äºç†è§£
2. æ¯ä¸ªç›¸å†Œè‡³å°‘åŒ…å« 3 ä¸ªèµ„äº§
3. ä¸è¦ä¸å·²æœ‰ç›¸å†Œé‡å¤
4. confidence è¡¨ç¤ºå»ºè®®çš„ç½®ä¿¡åº¦ (0-1)
5. åªè¿”å› JSONï¼Œä¸è¦å…¶ä»–å†…å®¹"""

        try:
            response = self.client.models.generate_content(
                model="gemini-2.5-flash",
                contents=prompt
            )
            
            text = response.text.strip()
            if text.startswith("```json"):
                text = text[7:]
            elif text.startswith("```"):
                text = text[3:]
            if text.endswith("```"):
                text = text[:-3]
            
            result = json.loads(text.strip())
            return result.get("suggestions", [])
            
        except Exception as e:
            print(f"Gemini ç›¸å†Œå»ºè®®å¤±è´¥: {e}")
            return []
    
    async def semantic_search_rerank(
        self,
        query: str,
        candidates: List[Dict[str, Any]],
        top_k: int = 20,
    ) -> List[Dict[str, Any]]:
        if not self.client or not candidates:
            return candidates[:top_k]
        
        prompt = f"""ç”¨æˆ·æœç´¢ï¼š"{query}"

å€™é€‰èµ„äº§ï¼š
{json.dumps(candidates[:50], ensure_ascii=False, indent=2)}

è¯·æ ¹æ®ç”¨æˆ·æœç´¢æ„å›¾ï¼Œå¯¹å€™é€‰èµ„äº§è¿›è¡Œç›¸å…³æ€§æ’åºã€‚

ä»¥ JSON æ ¼å¼è¿”å›æ’åºç»“æœï¼š
{{
    "ranked_ids": [èµ„äº§IDæŒ‰ç›¸å…³æ€§ä»é«˜åˆ°ä½æ’åˆ—],
    "explanation": "æ’åºç†ç”±"
}}

åªè¿”å› JSONï¼Œä¸è¦å…¶ä»–å†…å®¹"""

        try:
            response = self.client.models.generate_content(
                model="gemini-2.5-flash",
                contents=prompt
            )
            
            text = response.text.strip()
            if text.startswith("```json"):
                text = text[7:]
            elif text.startswith("```"):
                text = text[3:]
            if text.endswith("```"):
                text = text[:-3]
            
            result = json.loads(text.strip())
            ranked_ids = result.get("ranked_ids", [])
            
            # æŒ‰æ’åºç»“æœé‡æ–°æ’åˆ—
            id_to_candidate = {c["id"]: c for c in candidates}
            ranked = []
            for asset_id in ranked_ids[:top_k]:
                if asset_id in id_to_candidate:
                    ranked.append(id_to_candidate[asset_id])
            
            return ranked
            
        except Exception as e:
            print(f"Gemini é‡æ’åºå¤±è´¥: {e}")
            return candidates[:top_k]


    async def chat_with_tools(
        self,
        messages: List[Dict[str, str]],
        available_tools: List[Any],
        db: Any,
        current_user: Any,
    ) -> Dict[str, Any]:
        """
        å…·æœ‰å·¥å…·è°ƒç”¨èƒ½åŠ›çš„å¯¹è¯æ¨¡å‹
        """
        if not self.client:
            return {"content": "AI æœåŠ¡æœªé…ç½®", "role": "bot"}

        from google.genai import types
        
        # è½¬æ¢å·¥å…·å®šä¹‰ä¸º Gemini æ ¼å¼
        gemini_tools = []
        for tool in available_tools:
            gemini_tools.append(types.Tool(
                function_declarations=[
                    types.FunctionDeclaration(
                        name=tool.name,
                        description=tool.description,
                        parameters=tool.input_schema
                    )
                ]
            ))

        # å‡†å¤‡å†å²æ¶ˆæ¯
        history = []
        for msg in messages[:-1]:
            history.append(types.Content(
                role="user" if msg["role"] == "user" else "model",
                parts=[types.Part(text=msg["content"])]
            ))

        try:
            # åˆ›å»ºä¼šè¯
            chat = self.client.chats.create(
                model="gemini-2.5-flash",
                config=types.GenerateContentConfig(
                    tools=gemini_tools,
                    system_instruction="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å›¾ç‰‡ç®¡ç†åŠ©æ‰‹ã€‚ä½ å¯ä»¥é€šè¿‡å·¥å…·æœç´¢å›¾ç‰‡ã€æ›´æ–°å…ƒæ•°æ®ã€ç®¡ç†ç›¸å†Œç­‰ã€‚è¯·ä¼˜å…ˆä½¿ç”¨å·¥å…·æ¥è·å–å‡†ç¡®ä¿¡æ¯ï¼Œå¹¶åœ¨æ“ä½œåç»™ç”¨æˆ·æ˜ç¡®çš„åé¦ˆã€‚"
                ),
                history=history
            )

            # å‘é€å½“å‰æ¶ˆæ¯
            response = chat.send_message(messages[-1]["content"])
            
            # å¤„ç†å·¥å…·è°ƒç”¨å¾ªç¯
            all_tool_results = []
            
            while response.candidates[0].content.parts and any(p.function_call for p in response.candidates[0].content.parts):
                tool_results = []
                for part in response.candidates[0].content.parts:
                    if part.function_call:
                        call = part.function_call
                        print(f"ğŸ¤– AI è¯·æ±‚è°ƒç”¨å·¥å…·: {call.name} å‚æ•°: {call.args}")
                        
                        # æ‰§è¡Œå·¥å…·é€»è¾‘
                        from src.routers.mcp import call_tool, MCPCallRequest
                        mcp_req = MCPCallRequest(name=call.name, arguments=call.args)
                        mcp_res = await call_tool(mcp_req, db, current_user)
                        
                        # è®°å½•ç»“æœä¾›å‰ç«¯å±•ç¤º
                        all_tool_results.append({
                            "tool": call.name,
                            "args": call.args,
                            "result": mcp_res.content
                        })
                        
                        # è½¬æ¢ç»“æœç»™æ¨¡å‹
                        tool_results.append(types.Part(
                            function_response=types.FunctionResponse(
                                name=call.name,
                                response={"result": mcp_res.content}
                            )
                        ))
                
                # å°†å·¥å…·ç»“æœå‘é€å›æ¨¡å‹è·å–æœ€ç»ˆå›å¤
                response = chat.send_message(tool_results)

            return {
                "content": response.text,
                "role": "bot",
                "tool_results": all_tool_results
            }

        except Exception as e:
            print(f"Gemini Tool-Chat å¤±è´¥: {e}")
            return {"content": f"å¯¹è¯å‘ç”Ÿé”™è¯¯: {str(e)}", "role": "bot"}

# å•ä¾‹
gemini_service = GeminiService()
